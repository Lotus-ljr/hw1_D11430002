Q1: 分析淺層神經網路及深度神經網路對訓練資料集及測試資料集之預測績效的影響(課程投影片 DP06 Page34)：分析不同的隱藏層數量及節點數量之影響

Q2: 分析隱藏層的激活函數使用 Sigmoid、Softplus 或 ReLU，對訓練資料集及測試資料集之預測績效的影響(DP06 Pages16, 19)

Q3: 分析設定不同的 batch size 及 epoch，對訓練模型所需之訓練時間以及模型預測績效之影響(DP06 Page 29)

========== MNIST實驗結果分析 ==========
1. 網絡深度實驗結果:
  淺層網絡 (1層): 測試準確率 = 0.9776, 訓練時間 = 12.33秒
  中層網絡 (2層): 測試準確率 = 0.9796, 訓練時間 = 13.83秒
  深層網絡 (4層): 測試準確率 = 0.9760, 訓練時間 = 16.59秒

分析：從實驗結果可以觀察到，中層網絡(2層)達到了最高的測試準確率(0.9796)，而深層網絡(4層)的準確率(0.9760)反而略低於中層網絡，甚至比淺層網絡(0.9776)還低。這表明對於MNIST這樣相對簡單的任務，過度增加網絡深度不僅無法持續提升性能，反而可能導致性能下降。同時，網絡深度越大，訓練時間也隨之增加，從淺層的12.33秒增加到深層的16.59秒。

2. 激活函數實驗結果:
  Sigmoid: 測試準確率 = 0.9723, 訓練時間 = 16.87秒
  ReLU: 測試準確率 = 0.9758, 訓練時間 = 22.22秒
  Softplus: 測試準確率 = 0.9729, 訓練時間 = 13.25秒

分析: 比較三種激活函數的結果顯示，ReLU函數達到了最高的測試準確率(0.9758)，但其訓練時間(22.22秒)反而是最長的，這與理論預期有所不同。Sigmoid函數的準確率(0.9723)略低，訓練時間為16.87秒。Softplus作為ReLU的平滑版本，雖然準確率(0.9729)介於兩者之間，但在三種函數中展現出最佳的訓練效率，僅需13.25秒。

3. 批次大小和訓練輪數實驗結果:
  批次=16, 輪數=5: 測試準確率 = 0.9788, 訓練時間 = 36.19秒
  批次=128, 輪數=5: 測試準確率 = 0.9769, 訓練時間 = 6.60 秒
  批次=64, 輪數=10: 測試準確率 = 0.9730, 訓練時間 = 30.90秒
  批次=64, 輪數=20: 測試準確率 = 0.9780, 訓練時間 = 47.27秒

分析: 實驗結果顯示，批次大小和訓練輪數對模型性能和訓練效率有顯著影響。小批次(16)配合較短訓練(5輪)達到了較高的準確率(0.9788)，但訓練時間(36.19秒)較長。大批次(128)在相同輪數下準確率略低(0.9769)，但訓練時間大幅縮短至僅6.60秒，效率提升顯著。中批次(64)在10輪訓練下的準確率(0.9730)反而是最低的，但增加到20輪後，準確率提升至0.9780，接近小批次的水平，但訓練時間增至47.27秒。

========== Boston房價實驗結果分析 ==========
1. 網絡深度實驗結果:
  淺層網絡 (1層): 測試MAE = 4.2294, 測試RMSE = 5.4352, 測試MAPE = 23.6407%, 訓練時間 = 6.27秒
  中層網絡 (2層): 測試MAE = 3.2759, 測試RMSE = 4.8181, 測試MAPE = 16.7424%, 訓練時間 = 5.72秒
  深層網絡 (4層): 測試MAE = 2.5267, 測試RMSE = 4.0197, 測試MAPE = 12.2921%, 訓練時間 = 6.08秒

分析:隨著網絡深度增加，預測準確性明顯提高。深層網絡(4層)表現最佳，MAE為2.5267，比淺層網絡(4.2294)降低約40%，MAPE從23.6407%降至12.2921%。增加深度導致訓練時間略微變化（從6.27秒到6.08秒），但模型精度顯著提升，表明對房價預測這類複雜問題，深層網絡確實更有效。

2. 激活函數實驗結果:
  Sigmoid: 測試MAE = 5.8441, 測試RMSE = 8.6898, 測試MAPE = 25.4976%, 訓練時間 = 6.97秒
  ReLU: 測試MAE = 3.1748, 測試RMSE = 4.7869, 測試MAPE = 15.9137%, 訓練時間 = 7.73 秒
  Softplus: 測試MAE = 3.2749, 測試RMSE = 4.9243, 測試MAPE = 16.8373%, 訓練時間 = 7.61秒

分析: ReLU和Softplus表現接近且明顯優於Sigmoid。ReLU的MAE為3.1748，MAPE為15.9137%；Softplus指標相近，MAE為3.2749，MAPE為16.8373%。Sigmoid表現最差，MAE高達5.8441，MAPE達25.4976%。數據清晰顯示，在非線性回歸問題中，ReLU類激活函數明顯優於Sigmoid。

3. 批次大小和訓練輪數實驗結果:
  批次=16, 輪數=5: 測試MAE = 6.0275, 測試RMSE = 7.7888, 測試MAPE = 32.2439%, 訓練時間 = 1.92秒
  批次=128, 輪數=5: 測試MAE = 21.5195, 測試RMSE = 23.3735, 測試MAPE = 91.4815%, 訓練時間 = 1.81秒
  批次=64, 輪數=10: 測試MAE = 12.9584, 測試RMSE = 15.0753, 測試MAPE = 54.2493%, 訓練時間 = 2.29秒
  批次=64, 輪數=20: 測試MAE = 4.6819, 測試RMSE = 6.0048, 測試MAPE = 26.1805%, 訓練時間 = 3.19秒

分析: 小批次(16)在短訓練(5輪)下表現相對合理（MAE為6.0275），而大批次(128)表現極差（MAE高達21.5195）。中批次(64)需增加至20輪才達到較好性能（MAE降至4.6819）。由於數據集規模有限（506樣本），大批次導致模型更新不充分，不足以有效學習數據特徵，這表明小規模數據集應選擇較小批次大小或增加訓練輪數以提升模型性能。
